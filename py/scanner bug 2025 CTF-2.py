#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import asyncio
import aiohttp
import sqlite3
import csv
import json
import time
import re
import argparse
from urllib.parse import urljoin, urlparse, parse_qs
from bs4 import BeautifulSoup
from datetime import datetime
import ssl
import warnings
warnings.filterwarnings("ignore")

class AdvancedVulnerabilityScanner:
    def __init__(self, target_url, profile="bounty", threads=20, timeout=10):
        self.target_url = target_url.rstrip('/')
        self.domain = urlparse(target_url).netloc
        self.profile = profile.lower()
        self.threads = threads
        self.timeout = timeout
        self.vulnerabilities = []
        self.crawled_urls = set()
        self.scanned_urls = set()
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø±ÙˆÙØ§ÛŒÙ„
        self.setup_profile()
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª SSL
        self.ssl_context = ssl.create_default_context()
        self.ssl_context.check_hostname = False
        self.ssl_context.verify_mode = ssl.CERT_NONE
        
        # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡
        self.setup_database()

    def setup_profile(self):
        """ØªÙ†Ø¸ÛŒÙ… Ù¾Ø±ÙˆÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù"""
        if self.profile == "ctf":
            self.keywords = [
                'flag', 'admin', 'secret', 'hidden', 'debug', 'test', 'dev',
                'config', 'backup', 'temp', 'old', 'bak', 'tmp', 'log'
            ]
            self.suspicious_paths = [
                '/flag.txt', '/admin', '/secret', '/hidden', '/debug',
                '/config.php', '/backup', '/.git', '/.svn', '/robots.txt',
                '/sitemap.xml', '/.htaccess', '/web.config', '/flag',
                '/key.txt', '/password.txt', '/users.txt', '/admin.php'
            ]
            self.vulnerability_patterns = {
                'flag_disclosure': [
                    r'flag\{[^}]+\}',
                    r'CTF\{[^}]+\}',
                    r'FLAG\{[^}]+\}',
                    r'[a-f0-9]{32}',  # MD5 hash
                    r'[a-f0-9]{40}',  # SHA1 hash
                ],
                'sensitive_files': [
                    r'\.git', r'\.svn', r'\.env', r'config\.php',
                    r'backup\.', r'\.bak', r'\.old', r'\.tmp'
                ]
            }
        else:  # Bug Bounty profile
            self.keywords = [
                'main', 'app', 'runtime', 'bundle', 'polyfills', 'auth', 'config',
                'settings', 'local', 'dev', 'data', 'api', 'session', 'user',
                'core', 'client', 'server', 'utils', 'base', 'admin', 'login'
            ]
            self.suspicious_paths = [
                '/admin', '/login', '/auth', '/api', '/config', '/settings',
                '/dev', '/test', '/debug', '/backup', '/.env', '/config.json',
                '/web.config', '/app.config', '/settings.py', '/local.py',
                '/main.js', '/app.js', '/bundle.js', '/runtime.js',
                '/api/v1', '/api/v2', '/graphql', '/swagger', '/docs'
            ]
            self.vulnerability_patterns = {
                'hardcoded_credentials': [
                    r'password\s*[=:]\s*["\']([^"\']+)["\']',
                    r'api[_-]?key\s*[=:]\s*["\']([^"\']+)["\']',
                    r'secret\s*[=:]\s*["\']([^"\']+)["\']',
                    r'token\s*[=:]\s*["\']([^"\']+)["\']'
                ],
                'jwt_secrets': [
                    r'jwt[_-]?secret\s*[=:]\s*["\']([^"\']+)["\']',
                    r'eyJ[A-Za-z0-9-_=]+\.[A-Za-z0-9-_=]+\.?[A-Za-z0-9-_.+/=]*'
                ],
                'xss_vectors': [
                    r'<script[^>]*>.*?</script>',
                    r'javascript:',
                    r'on\w+\s*=',
                    r'eval\s*\(',
                    r'innerHTML\s*='
                ],
                'sql_injection': [
                    r'union\s+select',
                    r'order\s+by\s+\d+',
                    r'\'.*or.*\'.*=.*\'',
                    r'sleep\(\d+\)',
                    r'benchmark\('
                ]
            }

    def setup_database(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ SQLite"""
        self.db_name = f"scan_results_{int(time.time())}.db"
        self.conn = sqlite3.connect(self.db_name, check_same_thread=False)
        cursor = self.conn.cursor()
        
        # Ø¬Ø¯ÙˆÙ„ URL Ù‡Ø§ÛŒ Ú©Ø±Ø§Ù„ Ø´Ø¯Ù‡
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS crawled_urls (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                url TEXT UNIQUE,
                status_code INTEGER,
                content_type TEXT,
                content_length INTEGER,
                response_time REAL,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Ø¬Ø¯ÙˆÙ„ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒâ€ŒÙ‡Ø§
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS vulnerabilities (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                url TEXT,
                vulnerability_type TEXT,
                severity TEXT,
                description TEXT,
                payload TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        self.conn.commit()

    async def create_session(self):
        """Ø§ÛŒØ¬Ø§Ø¯ session Ø¨Ø±Ø§ÛŒ aiohttp"""
        connector = aiohttp.TCPConnector(
            limit=100,
            limit_per_host=30,
            ssl=self.ssl_context
        )
        
        timeout = aiohttp.ClientTimeout(total=self.timeout)
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        return aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers=headers
        )

    async def fetch_url(self, session, url):
        """Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØªÙˆØ§ÛŒ ÛŒÚ© URL"""
        try:
            start_time = time.time()
            async with session.get(url) as response:
                content = await response.text()
                response_time = time.time() - start_time
                
                # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡
                cursor = self.conn.cursor()
                cursor.execute('''
                    INSERT OR REPLACE INTO crawled_urls 
                    (url, status_code, content_type, content_length, response_time)
                    VALUES (?, ?, ?, ?, ?)
                ''', (
                    url, 
                    response.status,
                    response.headers.get('content-type', ''),
                    len(content),
                    response_time
                ))
                self.conn.commit()
                
                return {
                    'url': url,
                    'status': response.status,
                    'headers': dict(response.headers),
                    'content': content,
                    'response_time': response_time
                }
        except Exception as e:
            print(f"[-] Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª {url}: {e}")
            return None

    async def crawl_website(self, session):
        """Ú©Ø±Ø§Ù„ Ú©Ø±Ø¯Ù† ÙˆØ¨â€ŒØ³Ø§ÛŒØª"""
        print(f"[+] Ø´Ø±ÙˆØ¹ Ú©Ø±Ø§Ù„ {self.target_url}")
        
        # Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ
        main_page = await self.fetch_url(session, self.target_url)
        if not main_page:
            return
        
        soup = BeautifulSoup(main_page['content'], 'html.parser')
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§
        links = set()
        for tag in soup.find_all(['a', 'script', 'link', 'img', 'form']):
            href = tag.get('href') or tag.get('src') or tag.get('action')
            if href:
                full_url = urljoin(self.target_url, href)
                if self.domain in full_url:
                    links.add(full_url)
        
        # Ú©Ø±Ø§Ù„ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡
        semaphore = asyncio.Semaphore(self.threads)
        tasks = []
        
        for link in links:
            if link not in self.crawled_urls:
                self.crawled_urls.add(link)
                task = self.crawl_single_url(session, semaphore, link)
                tasks.append(task)
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)

    async def crawl_single_url(self, session, semaphore, url):
        """Ú©Ø±Ø§Ù„ ÛŒÚ© URL Ù…Ø´Ø®Øµ"""
        async with semaphore:
            result = await self.fetch_url(session, url)
            if result and result['status'] == 200:
                await self.analyze_response(result)

    async def scan_suspicious_paths(self, session):
        """Ø§Ø³Ú©Ù† Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ø´Ú©ÙˆÚ©"""
        print(f"[+] Ø§Ø³Ú©Ù† Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ø´Ú©ÙˆÚ©")
        
        semaphore = asyncio.Semaphore(self.threads)
        tasks = []
        
        # Ø§Ø³Ú©Ù† Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø§Ø² Ù¾ÛŒØ´ ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡
        for path in self.suspicious_paths:
            url = urljoin(self.target_url, path)
            if url not in self.scanned_urls:
                self.scanned_urls.add(url)
                task = self.scan_single_url(session, semaphore, url)
                tasks.append(task)
        
        # Ø§Ø³Ú©Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§
        extensions = ['.js', '.json', '.xml', '.txt', '.php', '.asp', '.jsp']
        for keyword in self.keywords:
            for ext in extensions:
                url = urljoin(self.target_url, f'/{keyword}{ext}')
                if url not in self.scanned_urls:
                    self.scanned_urls.add(url)
                    task = self.scan_single_url(session, semaphore, url)
                    tasks.append(task)
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)

    async def scan_single_url(self, session, semaphore, url):
        """Ø§Ø³Ú©Ù† ÛŒÚ© URL Ù…Ø´Ø®Øµ"""
        async with semaphore:
            result = await self.fetch_url(session, url)
            if result:
                await self.analyze_response(result)

    async def analyze_response(self, response_data):
        """ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ù¾Ø§Ø³Ø® Ø¯Ø±ÛŒØ§ÙØªÛŒ"""
        url = response_data['url']
        content = response_data['content']
        headers = response_data['headers']
        status = response_data['status']
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù¾Ø§Ø³Ø®
        if status in [403][401]:
            await self.add_vulnerability(
                url, "Access Control", 
                f"Protected resource: HTTP {status}", 
                "Medium"
            )
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ
        await self.check_security_headers(url, headers)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ
        await self.check_vulnerability_patterns(url, content)
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JavaScript
        if url.endswith('.js') or 'javascript' in headers.get('content-type', ''):
            await self.analyze_javascript(url, content)

    async def check_security_headers(self, url, headers):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ"""
        security_headers = {
            'X-Frame-Options': 'Clickjacking protection missing',
            'X-XSS-Protection': 'XSS protection disabled',
            'X-Content-Type-Options': 'MIME sniffing protection missing',
            'Strict-Transport-Security': 'HSTS not implemented',
            'Content-Security-Policy': 'CSP not implemented'
        }
        
        for header, description in security_headers.items():
            if header not in headers:
                await self.add_vulnerability(
                    url, "Security Headers", description, "Low"
                )

    async def check_vulnerability_patterns(self, url, content):
        """Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ"""
        for vuln_type, patterns in self.vulnerability_patterns.items():
            for pattern in patterns:
                matches = re.findall(pattern, content, re.IGNORECASE | re.MULTILINE)
                if matches:
                    severity = self.get_severity(vuln_type)
                    description = f"Found {len(matches)} matches for {vuln_type}"
                    
                    # Ø§Ú¯Ø± flag Ù¾ÛŒØ¯Ø§ Ø´Ø¯ØŒ Ø¢Ù† Ø±Ø§ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø¯Ù‡
                    if 'flag' in vuln_type.lower() and matches:
                        description += f" - Potential flags: {matches[:3]}"
                    
                    await self.add_vulnerability(
                        url, vuln_type.replace('_', ' ').title(),
                        description, severity, str(matches[:3])
                    )

    async def analyze_javascript(self, url, content):
        """ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JavaScript"""
        js_patterns = {
            'api_endpoints': r'(?i)(https?://[^\s"\']+/api/[^\s"\']*)',
            'sensitive_data': r'(?i)(password|secret|key|token)\s*[=:]\s*["\']([^"\']{5,})["\']',
            'debug_info': r'(?i)(console\.log|debugger|alert)\s*\(',
            'ajax_calls': r'(?i)\$\.ajax\s*\(|\$\.get\s*\(|\$\.post\s*\(',
        }
        
        for pattern_type, pattern in js_patterns.items():
            matches = re.findall(pattern, content)
            if matches:
                severity = "High" if "sensitive" in pattern_type else "Medium"
                await self.add_vulnerability(
                    url, f"JavaScript {pattern_type.replace('_', ' ').title()}",
                    f"Found {len(matches)} {pattern_type} in JavaScript",
                    severity, str(matches[:3])
                )

    def get_severity(self, vuln_type):
        """ØªØ¹ÛŒÛŒÙ† Ø´Ø¯Øª Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ"""
        high_severity = ['hardcoded_credentials', 'jwt_secrets', 'flag_disclosure', 'sql_injection']
        medium_severity = ['xss_vectors', 'sensitive_files', 'api_endpoints']
        
        if vuln_type in high_severity:
            return "High"
        elif vuln_type in medium_severity:
            return "Medium"
        else:
            return "Low"

    async def add_vulnerability(self, url, vuln_type, description, severity, payload=""):
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ"""
        vulnerability = {
            'url': url,
            'type': vuln_type,
            'description': description,
            'severity': severity,
            'payload': payload,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        self.vulnerabilities.append(vulnerability)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡
        cursor = self.conn.cursor()
        cursor.execute('''
            INSERT INTO vulnerabilities 
            (url, vulnerability_type, severity, description, payload)
            VALUES (?, ?, ?, ?, ?)
        ''', (url, vuln_type, severity, description, payload))
        self.conn.commit()
        
        print(f"[{severity}] {vuln_type}: {url}")

    def generate_csv_report(self, filename=None):
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ CSV"""
        if not filename:
            filename = f'{self.profile}_scan_report_{int(time.time())}.csv'
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù‡Ù…ÛŒØª
        severity_order = {'High': 1, 'Medium': 2, 'Low': 3}
        sorted_vulns = sorted(self.vulnerabilities, 
                            key=lambda x: severity_order.get(x['severity'], 4))
        
        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['timestamp', 'severity', 'type', 'url', 'description', 'payload']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for vuln in sorted_vulns:
                writer.writerow(vuln)
        
        print(f"[+] Ú¯Ø²Ø§Ø±Ø´ CSV Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filename}")
        return filename

    def generate_html_report(self, filename=None):
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ HTML"""
        if not filename:
            filename = f'{self.profile}_scan_report_{int(time.time())}.html'
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù‡Ù…ÛŒØª
        severity_order = {'High': 1, 'Medium': 2, 'Low': 3}
        sorted_vulns = sorted(self.vulnerabilities, 
                            key=lambda x: severity_order.get(x['severity'], 4))
        
        # Ø¢Ù…Ø§Ø±
        high_count = len([v for v in sorted_vulns if v['severity'] == 'High'])
        medium_count = len([v for v in sorted_vulns if v['severity'] == 'Medium'])
        low_count = len([v for v in sorted_vulns if v['severity'] == 'Low'])
        
        html_content = f"""
        <!DOCTYPE html>
        <html dir="rtl" lang="fa">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Ú¯Ø²Ø§Ø±Ø´ Ø§Ø³Ú©Ù† {self.profile.upper()} - {self.domain}</title>
            <style>
                body {{ font-family: 'Tahoma', Arial, sans-serif; margin: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; }}
                .container {{ max-width: 1200px; margin: 0 auto; }}
                .header {{ background: rgba(255,255,255,0.95); color: #333; padding: 30px; border-radius: 15px; margin-bottom: 20px; box-shadow: 0 10px 30px rgba(0,0,0,0.3); }}
                .profile-badge {{ display: inline-block; background: #e74c3c; color: white; padding: 5px 15px; border-radius: 20px; font-size: 12px; margin-left: 10px; }}
                .summary {{ background: rgba(255,255,255,0.95); padding: 20px; border-radius: 15px; margin-bottom: 20px; box-shadow: 0 5px 15px rgba(0,0,0,0.2); }}
                .vulnerability {{ background: rgba(255,255,255,0.95); margin: 15px 0; padding: 20px; border-radius: 15px; box-shadow: 0 5px 15px rgba(0,0,0,0.2); }}
                .high {{ border-left: 6px solid #e74c3c; }}
                .medium {{ border-left: 6px solid #f39c12; }}
                .low {{ border-left: 6px solid #27ae60; }}
                .severity {{ font-weight: bold; padding: 8px 15px; border-radius: 20px; color: white; display: inline-block; }}
                .severity.high {{ background: linear-gradient(45deg, #e74c3c, #c0392b); }}
                .severity.medium {{ background: linear-gradient(45deg, #f39c12, #e67e22); }}
                .severity.low {{ background: linear-gradient(45deg, #27ae60, #229954); }}
                .url {{ color: #3498db; word-break: break-all; background: #f8f9fa; padding: 5px 10px; border-radius: 5px; }}
                .stats {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; }}
                .stat {{ background: linear-gradient(45deg, #3498db, #2980b9); color: white; padding: 20px; border-radius: 10px; text-align: center; }}
                .payload {{ background: #2c3e50; color: #ecf0f1; padding: 10px; border-radius: 5px; font-family: monospace; margin-top: 10px; }}
                .filter-buttons {{ margin: 20px 0; }}
                .filter-btn {{ background: #34495e; color: white; border: none; padding: 10px 20px; margin: 5px; border-radius: 5px; cursor: pointer; }}
                .filter-btn.active {{ background: #e74c3c; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>ğŸ” Ú¯Ø²Ø§Ø±Ø´ Ø§Ø³Ú©Ù† Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ <span class="profile-badge">{self.profile.upper()}</span></h1>
                    <p><strong>Ù‡Ø¯Ù:</strong> {self.target_url}</p>
                    <p><strong>ØªØ§Ø±ÛŒØ® Ø§Ø³Ú©Ù†:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
                    <p><strong>ØªØ¹Ø¯Ø§Ø¯ URL Ù‡Ø§ÛŒ Ú©Ø±Ø§Ù„ Ø´Ø¯Ù‡:</strong> {len(self.crawled_urls)}</p>
                </div>
                
                <div class="summary">
                    <h2>ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬</h2>
                    <div class="stats">
                        <div class="stat">
                            <h3>{high_count}</h3>
                            <p>Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ Ø¨Ø­Ø±Ø§Ù†ÛŒ</p>
                        </div>
                        <div class="stat">
                            <h3>{medium_count}</h3>
                            <p>Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ Ù…ØªÙˆØ³Ø·</p>
                        </div>
                        <div class="stat">
                            <h3>{low_count}</h3>
                            <p>Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ Ú©Ù…</p>
                        </div>
                        <div class="stat">
                            <h3>{len(sorted_vulns)}</h3>
                            <p>Ú©Ù„ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒâ€ŒÙ‡Ø§</p>
                        </div>
                    </div>
                </div>
                
                <div class="filter-buttons">
                    <button class="filter-btn active" onclick="filterVulns('all')">Ù‡Ù…Ù‡</button>
                    <button class="filter-btn" onclick="filterVulns('high')">Ø¨Ø­Ø±Ø§Ù†ÛŒ</button>
                    <button class="filter-btn" onclick="filterVulns('medium')">Ù…ØªÙˆØ³Ø·</button>
                    <button class="filter-btn" onclick="filterVulns('low')">Ú©Ù…</button>
                </div>
                
                <h2>ğŸš¨ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒâ€ŒÙ‡Ø§</h2>
        """
        
        for vuln in sorted_vulns:
            payload_html = f'<div class="payload"><strong>Payload:</strong> {vuln["payload"]}</div>' if vuln['payload'] else ''
            html_content += f"""
            <div class="vulnerability {vuln['severity'].lower()}" data-severity="{vuln['severity'].lower()}">
                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 15px;">
                    <h3>{vuln['type']}</h3>
                    <span class="severity {vuln['severity'].lower()}">{vuln['severity']}</span>
                </div>
                <p><strong>URL:</strong> <span class="url">{vuln['url']}</span></p>
                <p><strong>ØªÙˆØ¶ÛŒØ­Ø§Øª:</strong> {vuln['description']}</p>
                <p><strong>Ø²Ù…Ø§Ù† Ú©Ø´Ù:</strong> {vuln['timestamp']}</p>
                {payload_html}
            </div>
            """
        
        html_content += """
                <script>
                    function filterVulns(severity) {
                        const vulns = document.querySelectorAll('.vulnerability');
                        const buttons = document.querySelectorAll('.filter-btn');
                        
                        buttons.forEach(btn => btn.classList.remove('active'));
                        event.target.classList.add('active');
                        
                        vulns.forEach(vuln => {
                            if (severity === 'all' || vuln.dataset.severity === severity) {
                                vuln.style.display = 'block';
                            } else {
                                vuln.style.display = 'none';
                            }
                        });
                    }
                </script>
            </div>
        </body>
        </html>
        """
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"[+] Ú¯Ø²Ø§Ø±Ø´ HTML Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filename}")
        return filename

    async def run_scan(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ù† Ú©Ø§Ù…Ù„"""
        print(f"[+] Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ù† {self.profile.upper()} Ø¨Ø±Ø§ÛŒ {self.target_url}")
        print(f"[+] Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² {self.threads} concurrent connections")
        
        start_time = time.time()
        
        async with await self.create_session() as session:
            # Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù† Ú©Ø±Ø§Ù„ Ùˆ Ø§Ø³Ú©Ù†
            await asyncio.gather(
                self.crawl_website(session),
                self.scan_suspicious_paths(session)
            )
        
        end_time = time.time()
        
        print(f"\n[+] Ø§Ø³Ú©Ù† ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯ Ø¯Ø± {end_time - start_time:.2f} Ø«Ø§Ù†ÛŒÙ‡")
        print(f"[+] ØªØ¹Ø¯Ø§Ø¯ URL Ù‡Ø§ÛŒ Ú©Ø±Ø§Ù„ Ø´Ø¯Ù‡: {len(self.crawled_urls)}")
        print(f"[+] ØªØ¹Ø¯Ø§Ø¯ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡: {len(self.vulnerabilities)}")
        
        # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§
        if self.vulnerabilities:
            csv_file = self.generate_csv_report()
            html_file = self.generate_html_report()
            print(f"[+] Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {self.db_name}")
            return csv_file, html_file, self.db_name
        else:
            print("[-] Ù‡ÛŒÚ† Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
            return None, None, self.db_name

    def __del__(self):
        """Ø¨Ø³ØªÙ† Ø§ØªØµØ§Ù„ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡"""
        if hasattr(self, 'conn'):
            self.conn.close()

async def main():
    parser = argparse.ArgumentParser(description='Ø§Ø³Ú©Ù†Ø± Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ Ø¨Ø§ Async Crawler')
    parser.add_argument('url', help='URL Ù‡Ø¯Ù Ø¨Ø±Ø§ÛŒ Ø§Ø³Ú©Ù†')
    parser.add_argument('-p', '--profile', choices=['ctf', 'bounty'], default='bounty', 
                       help='Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø§Ø³Ú©Ù† (ctf ÛŒØ§ bounty)')
    parser.add_argument('-t', '--threads', type=int, default=20, 
                       help='ØªØ¹Ø¯Ø§Ø¯ Ø§ØªØµØ§Ù„Ø§Øª Ù‡Ù…Ø²Ù…Ø§Ù† (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 20)')
    parser.add_argument('--timeout', type=int, default=10, 
                       help='timeout Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 10)')
    
    args = parser.parse_args()
    
    if not args.url.startswith(('http://', 'https://')):
        args.url = 'https://' + args.url
    
    scanner = AdvancedVulnerabilityScanner(
        args.url, 
        args.profile, 
        args.threads, 
        args.timeout
    )
    
    try:
        await scanner.run_scan()
    except KeyboardInterrupt:
        print("\n[!] Ø§Ø³Ú©Ù† ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯")
    except Exception as e:
        print(f"[-] Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ù†: {e}")

if __name__ == "__main__":
    asyncio.run(main())
